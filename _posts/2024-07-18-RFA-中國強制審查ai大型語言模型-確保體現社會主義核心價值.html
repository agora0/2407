---
layout: post
title: 中國強制審查AI大型語言模型 確保體現社會主義核心價值
date: 2024-07-17 16:00:00.000000000 +00:00
link: https://www.rfa.org/cantonese/news/ai-07182024031544.html
categories: rfa
---

<img src="https://www.rfa.org/cantonese/news/ai-07182024031544.html/@@images/664e720d-e83e-4336-b374-637a24ea59fb.jpeg" alt="中國強制審查AI大型語言模型　確保體現社會主義核心價值" title="中國強制審查AI大型語言模型　確保體現社會主義核心價值" width="100%" referrerpolicy="no-referrer">
                

                

               <span class="lead_image_caption">北京一間AI初創公司的員工指出，公司的基礎模型在回答問題時「十分不受約束」，所以進行安全過濾極為重要。</span>

                <div id="zoomattribute">
                  
                          <a id="single_image" href="https://www.rfa.org/cantonese/news/ai-07182024031544.html/@@images/image/social_media" data-fancybox="" data-caption="北京一間AI初創公司的員工指出，公司的基礎模型在回答問題時「十分不受約束」，所以進行安全過濾極為重要。" title="北京一間AI初創公司的員工指出，公司的基礎模型在回答問題時「十分不受約束」，所以進行安全過濾極為重要。">
                             <img src="https://www.rfa.org/++plone++rfa-resources/img/icon-zoom.png" referrerpolicy="no-referrer">
                          </a>
                  

                  
                  <span class="copyright">粵語組製圖</span>
                  
                  
               </div> <!-- zoomattribute -->
            
            

            
         <p>英國《金融時報》報道，中國加強審查人工智能（AI）大語言模型，以確保系統體現社會主義核心價值觀，審查會測試大語言模型對一系列問題的回答，當中不少涉及中國的敏感政治議題和國家主席習近平。</p>
<p>報道引述知情人士稱，網信辦已要求字節跳動（ByteDance）、阿里巴巴、月之暗面（Moonshot）和零一萬物（01.AI）等大型科技公司和人工智能初創公司，參與政府對人工智能模型的強制審查，除了測試對一系列問題的答案，審查還包括大語言模型的訓練數據和其他安全流程。</p>
<p>杭州一間人工智能公司的員工表示，網信辦有專門團隊負責測試，入到公司後，坐在會議室進行審查，公司的大型語言模型第一次未能通過審查，原因不太清楚，經過與同行研究猜測，花了數個月作出調整，第二次終於過關。</p>
<p><strong>基礎模型「十分不受約束」</strong></p>
<p>報道指出，當局嚴格的審批過程迫使人工智能公司迅速學會，如何把正在建立的大型語言模型審查做到最好。北京一間AI初創公司的員工指出，公司的基礎模型在回答問題時「十分不受約束」，所以進行安全過濾極為重要。要進行安全過濾，首先要把被認為有問題的資訊，從用來訓練的數據中剔除，並建立敏感關鍵字資料庫。</p>
<p>中國今年2月發布的人工智能企業營運指南稱，AI企業需要收集數千個違反「社會主義核心價值」的敏感關鍵字和問題，例如「煽動顛覆國家政權」或「破壞國家統一」，而敏感關鍵字應該每周更新一次。經審查的結果是，大多數中國聊天機械人都會拒絕回答一些敏感話題，例如1989年6月4日發生過甚麼事；另有業內人士指出，Moonshot的聊天機械人Kimi會拒絕回答大多數與習近平有關的問題。</p>
<p>編輯：李向陽（台北）　網編：池煥衡</p>
