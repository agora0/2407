---
layout: post
title: 人类与算法：网络新文化战争
date: 2024-07-31 17:36:01.000000000 +08:00
link: https://chinese.aljazeera.net/technology/2024/7/31/%e4%ba%ba%e7%b1%bb%e4%b8%8e%e7%ae%97%e6%b3%95%e7%bd%91%e7%bb%9c%e6%96%b0%e6%96%87%e5%8c%96%e6%88%98%e4%ba%89
categories: aj
---

<div aria-live="polite" aria-atomic="true"><p>从塑造我们阅读和购买的内容到诊断疾病，算法是指导我们整个在线体验的主要焦点，几乎不可能一天不与算法交互， 所以算法在我们生活的各个方面发挥着重要作用。</p>
<p>大约74%的美国成年人每天至少使用一次Facebook，他们看到的内容完全由专有算法决定。在线下，它们越来越多地被用来帮助我们做出艰难的决定、审查工作申请、监督考试结果等等。</p>
<p>随着算法变得越来越普遍，它们产生了炒作和焦虑，虽然我们被告知可能含糊且有偏见，但我们也听说它们非常有用。在这两种情况下，受益者或受害者都是人类，但问题依然存在：算法如何控制和指导人们的日常生活？</p>
<h3>算法如何影响我们的生活</h3>
<p>尽管近年来由于一些基于算法的内容平台的兴起，个性化推荐算法受到关注，但事实是搜索引擎和电商平台长期以来一直依赖推荐算法。这些算法服务的成功只有通过跟踪和记录你在服务上所做的每一个动作才有可能，因此算法社会的前提是数字化一切，甚至是人脑。</p>
<p>随着移动终端和智能穿戴设备的发展，不仅可以追踪身体发出的数据，例如记录、发布、浏览、购买记录等，还可以追踪身体本身的数据，例如追踪人脸、动作、视力和心跳。可以分析人们的现实生活需求和情感情况，以便根据不同的场景和目标为用户创建动态的“数字档案”或“算法身份”。</p>
<p>据美国《科学》杂志报道，人们与在线算法的日常互动会影响他们向他人学习的方式，从而产生负面后果，导致社会误解、冲突和错误信息的传播。</p>
<p>人们在社交媒体环境中与他人互动，而算法控制着他们看到的社交信息的流动，而算法部分地决定了社交媒体用户看到的消息、人物和想法。</p>
<p>在这些平台上，算法的主要目的是放大维持参与度的信息，这意味着它们使人们点击内容并返回平台。据该杂志称，这种设计的一个副作用是算法放大了人们最有可能从中学习的信息，我将其称为“主要信息”（PRIME）。</p>
<p>在我们的进化历史中，从初始信息中学习的偏见非常有用，向杰出人士学习是有效的，因为这些人是成功的并且可以被模仿。关心违反道德规范的人很重要，因为惩罚他们有助于社会保持合作。</p>
<p>但是，当原始信息被算法放大并且有些人利用算法放大来推销自己时，会发生什么？在这里，外表成为成功的坏信号，因为人们可以在社交媒体上伪造自己的外表，新闻文件充斥着负面和不道德的信息，以至于出现冲突而不是合作。</p>
<p>人类心理和算法放大的相互作用会导致功能障碍，因为社交学习支持协作和解决问题，但社交媒体算法旨在提高参与度。以算法为中介的社会学习功能失调的主要后果是人们开始对社交世界形成错误的认知。</p>
<figure id="attachment_763216" aria-describedby="caption-attachment-763216"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2024/07/GettyImages-1314526623-1722415899.jpg?w=770&amp;resize=770%2C513" alt="" data-recalc-dims="1"/><figcaption id="caption-attachment-763216">人工智能算法通过获取有助于算法学习的训练数据来工作<br/>(盖帝图像)</figcaption></figure>
<h3>算法获胜</h3>
<p>最强大的社交媒体、视频和购物平台都融合了通过个性化Spotify播放列表、TikTok上流行的“For You”页面（推荐页面）或亚马逊产品推荐来满足用户需求的理念，互联网竭尽全力对您的在线活动进行微观管理。</p>
<p>与此同时，人们对这种独裁技术方法的潜在危险的认识空前高涨。美国国会最近调查了社交媒体算法是否威胁儿童的福祉，新的研究和书籍还关注允许算法管理我们的新闻源所产生的广泛文化后果。</p>
<p>德雷克大学助理教授、爱荷华大学算法与文化研究小组成员瑞安·斯托尔特表示：“我认为它以我至少担心的方式证实了我们的很多文化品味。”</p>
<p>另一方面，昆士兰大学商学院数字经济系主任马雷克·科沃克维奇（Marek Kowalkiewicz）教授表示：“我们已经被算法包围，并且它们将继续增长。我的吸尘器有一个算法，可以告诉我何时更换刷子，我的汽车可以告诉我何时给轮胎充气，我的割草机在发生故障时会提醒我。所有这些消息都通过他们的应用程序显示在我的手机上。”</p>
<p>他补充道，“我坚信有一天我不用再去买咖啡豆了。咖啡机会知道咖啡量何时不足，并自动订购，然后通过无人机送到我家门口。我们可能根本不会去杂货店购物，因为我们的冰箱使用算法根据我们的口味和季节预测我们想要什么，并会计划一周的膳食并订购食品。”</p>
<p>他还称：“我将这些可以完成我们工作的自主算法称为数字小黄人，因为它们帮助我们完成我们经常避免做的重复且无聊的工作。”</p>
<p>另一方面，由于人们对大型科技公司的模糊推荐系统越来越感到不安，无算法的数字天堂正在出现，企业家泰勒·班布里奇（Tyler Bainbridge）参与了一场新兴运动，该运动试图开发风险较小的自动推荐替代方案，并且是 PI.FYI 的创始人，正如班布里奇所说，这个社交平台在一月份推出，希望“重组人类”。</p>
<p>班布里奇表示：“人们渴望这样的日子，即他们浏览的任何地方都不会受到个性化广告的轰炸。” 他的公司的收入来自用户订阅，起价为每月6美元。虽然它的设计让人想起旧版本的互联网，但班布里奇称他希望避免创建一个怀旧的界面。</p>
<h3>算法和人工智能</h3>
<p>人工智能依赖于算法，算法是告诉计算机如何自行学习和操作的编程。虽然通用算法可能很简单，但人工智能算法本质上更加复杂。</p>
<p>人工智能算法通过获取有助于算法学习的训练数据来工作。人工智能算法主要有 3 类：监督学习、无监督学习和强化学习。这些算法之间的主要区别在于它们的训练和工作方式。</p>
<p>因此，人工智能模型正在出现，其目标是帮助人类，但它可能会到达一个取代人类的危险阶段，在算法大发展的阶段必须保持警惕。</p>
</div><div>来源<!-- --> : <!-- -->半岛电视台</div>
